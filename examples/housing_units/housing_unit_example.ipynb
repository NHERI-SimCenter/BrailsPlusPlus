{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Inventory Generation with Probabilistic Housing Units\n",
    "\n",
    "This example demonstrates the **complete, end-to-end workflow** for generating a building\n",
    "inventory enriched with household-level demographic data.\n",
    "\n",
    "**Goal:**\n",
    "Starting from a simple location name (e.g., \"Tiburon, CA\"), we will:\n",
    "1.  Build a geometric inventory of building footprints.\n",
    "2.  Enrich it with physical attributes (e.g., year built, stories).\n",
    "3.  Populate residential buildings with probabilistic households (income, race, size)\n",
    "    statistically matched to the local US Census demographics.\n",
    "\n",
    "**Scope & Limitations:**\n",
    "- **USA Only:** This workflow relies on US-specific datasets (NSI, US Census).\n",
    "  It is not robust for international locations.\n",
    "- **Service Stability:** Public data APIs (NSI, Overture, Census) occasionally experience\n",
    "  downtime. If you encounter connection errors, please wait a few minutes and try again.\n",
    "- **Not Hazus-Ready:** While rich, this inventory is not yet formatted for a full\n",
    "  Hazus damage assessment. For Hazus-specific inferencing, please see the scripts\n",
    "  in `examples/inventory_creation`.\n",
    "\n",
    "**Flexibility:**\n",
    "While this script builds an inventory from scratch using BRAILS tools, you can bring\n",
    "your own! If you already have a GeoJSON building inventory with the required columns\n",
    "(Occupancy, PlanArea, Stories), you can simply load it using `AssetInventory.read_from_geojson()`\n",
    "and skip directly to **Step 6** to generate households."
   ],
   "id": "102f1715e4b5cc9b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Define the Region of Interest\n",
    "\n",
    "First, we define the geographic area for our analysis.\n",
    "The `RegionBoundary` class allows you to specify a region by its name (e.g., \"Berkeley, CA\")\n",
    "or by a bounding box coordinate tuple.\n",
    "\n",
    "**Options:**\n",
    "- To use a specific bounding box, change `type` to `'locationPolygon'` and provide\n",
    "  a tuple of `(min_longitude, min_latitude, max_longitude, max_latitude)` as `data`."
   ],
   "id": "55541b8a8b5e50bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from brails.types import RegionBoundary\n",
    "\n",
    "region_boundary_object = RegionBoundary(\n",
    "    {\n",
    "        \"type\": \"locationName\",\n",
    "        \"data\": \"Tiburon, CA\"\n",
    "    }\n",
    ")\n",
    "\n",
    "geometry, description, osm_id = region_boundary_object.get_boundary()\n",
    "display(geometry)"
   ],
   "id": "ac89a8449772ac18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Download Building Footprints (Geometry)\n",
    "\n",
    "We fetch the physical shapes of **building footprints** (polygons) from Overture Maps.\n",
    "Overture Maps combines data from open sources (OpenStreetMap) and commercial donors\n",
    "(Microsoft, Google, Meta) to provide high-quality building footprints.\n",
    "\n",
    "**Why we do this:**\n",
    "We strictly use this for the *geometry* of the buildings. We remove all other\n",
    "metadata to demonstrate how to build a rich inventory from scratch using\n",
    "just these raw shapes.\n",
    "\n",
    "**Alternative Providers:**\n",
    "There is no single \"best\" footprint provider for every location. Depending on the\n",
    "region, one source may be more complete or recent than another. We recommend\n",
    "inspecting the results from different providers:\n",
    "- `OSM_FootprintScraper`: Fetches data from OpenStreetMap.\n",
    "- `USA_FootprintScraper`: Fetches data from the **FEMA USA Structures** database."
   ],
   "id": "c08b8ce98f6f2e8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from brails.scrapers import OvertureMapsFootprintScraper\n",
    "\n",
    "bldg_inventory = OvertureMapsFootprintScraper({'length': 'ft'}).get_footprints(region_boundary_object)\n",
    "\n",
    "# only use the footprint geometry and remove all other metadata for clarity\n",
    "bldg_inventory.remove_features(bldg_inventory.get_all_asset_features())"
   ],
   "id": "ab439c6013b2146b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Download Building Attributes (Data)\n",
    "\n",
    "Next, we fetch detailed building attributes from the **National Structure Inventory (NSI)**.\n",
    "NSI is a US Army Corps of Engineers dataset designed for hazard modeling (e.g., flood damage).\n",
    "It integrates data from tax assessors, CoreLogic, and Census demographics.\n",
    "\n",
    "**Important Caveats:**\n",
    "- **Point Data:** NSI data is point-based, meaning each building is represented by a single\n",
    "  coordinate, not a shape.\n",
    "- **Inferred Data:** Many attributes (like foundation type or number of stories) are\n",
    "  often **imputed or inferred** based on regional averages rather than direct observation.\n",
    "  It is a statistical model, not ground truth.\n",
    "\n",
    "**Feature Selection:**\n",
    "We map NSI attributes to standard SimCenter naming conventions:\n",
    "- `found_type` -> `FoundationType`: (e.g., Slab, Crawlspace) Critical for flood vulnerability.\n",
    "- `found_ht` -> `FirstFloorElevation`: Height of the first floor above ground.\n",
    "- `sqft` -> `PlanArea`: The footprint area (often derived from tax records).\n",
    "- `num_story` -> `NumberOfStories`: Inferred from height or tax data.\n",
    "- `occtype` -> `OccupancyClass`: (e.g., RES1, COM1) The primary use of the building.\n",
    "- `pop2*` -> `Population`: Estimated day/night occupancy based on Census blocks.\n",
    "- `med_yr_blt` -> `YearBuilt`: Median year built for the area.\n",
    "- `students` -> `StudentPopulation`: Estimated student counts for schools.\n",
    "- `bldgtype` -> `BuildingType`: (e.g., Wood, Masonry) Structural material type."
   ],
   "id": "62b418ad85c8b58f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from brails.scrapers import NSI_Parser\n",
    "\n",
    "nsi_points = NSI_Parser().get_raw_data(region_boundary_object)\n",
    "\n",
    "# Rename the features we need later using standard SimCenter labels\n",
    "feature_rename_map = {\n",
    "    'fd_id': 'fd_id',\n",
    "    'type': 'type',\n",
    "    'bldgtype': 'BuildingType',\n",
    "    'found_type': 'FoundationType',\n",
    "    'found_ht': 'FirstFloorElevation',\n",
    "    'pop2amu65': 'NightPopulationUnder65',\n",
    "    'pop2amo65': 'NightPopulationOver65',\n",
    "    'pop2pmu65': 'DayPopulationUnder65',\n",
    "    'pop2pmo65': 'DayPopulationOver65',\n",
    "    'x': 'Longitude',\n",
    "    'y': 'Latitude',\n",
    "    'sqft': 'PlanArea',\n",
    "    'num_story': 'NumberOfStories',\n",
    "    'students': 'StudentPopulation',\n",
    "    'med_yr_blt': 'YearBuilt',\n",
    "    'occtype': 'OccupancyClass'\n",
    "}\n",
    "nsi_points.change_feature_names(feature_rename_map)\n",
    "\n",
    "# remove all other features for clarity\n",
    "features_to_remove = nsi_points.get_all_asset_features()\n",
    "features_to_remove.difference_update(feature_rename_map.values())\n",
    "nsi_points.remove_features(features_to_remove)"
   ],
   "id": "53031d0b4792d282",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Merge Attributes with Geometry\n",
    "\n",
    "We now have two datasets:\n",
    "1. **Polygons** (Shapes) from Overture Maps.\n",
    "2. **Points** (Data) from NSI.\n",
    "\n",
    "The `BasicPointsToPolygonsAllocator` spatially joins these sets. It assigns the attributes\n",
    "from an NSI point to the Overture footprint that contains it.\n",
    "\n",
    "**How it Works:**\n",
    "1. **Strict Inclusion:** By default, a point must fall strictly inside a polygon.\n",
    "2. **Convex Hull (`use_convex_hull=True`):** Complex building shapes (like U-shapes)\n",
    "   can cause valid centroids to fall \"outside\" the polygon. We use the convex hull\n",
    "   (the \"shrink wrap\" shape) to capture these points.\n",
    "3. **Buffer (`buffer_dist=10.0`):** We add a **10-meter** tolerance buffer to catch points that\n",
    "   might be slightly offset due to GPS errors or different data vintages.\n",
    "\n",
    "**Caveat:**\n",
    "This is a strict spatial join. NSI points that do not land within a footprint (even\n",
    "with the buffer) will be **dropped**. Conversely, footprints that contain no NSI points\n",
    "will remain in the inventory but will have no attribute data (missing features)."
   ],
   "id": "f97e03d826eec44d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from brails.aggregators import BasicPointsToPolygonsAllocator\n",
    "\n",
    "BasicPointsToPolygonsAllocator(\n",
    "    polygon_inventory=bldg_inventory,\n",
    "    point_inventory=nsi_points,\n",
    ").allocate(\n",
    "    use_convex_hull = True,\n",
    "    buffer_dist = 10.0\n",
    ")"
   ],
   "id": "12be7a0cec9ec7aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Impute Missing Data\n",
    "\n",
    "After the merge, our inventory is incomplete. Some footprints had no matching NSI point,\n",
    "leaving them with missing attributes (NaN). Even successfully matched buildings might\n",
    "have gaps in the original NSI data.\n",
    "\n",
    "The `KnnImputer` fills these gaps using a **K-Nearest Neighbors** approach. It assumes that\n",
    "nearby buildings are likely to be similar (e.g., neighbors often have similar\n",
    "year-built dates or story counts).\n",
    "\n",
    "**Key Options:**\n",
    "- `n_possible_worlds`: How many different imputed \"versions\" of the inventory to generate.\n",
    "  We use `1` for a single deterministic best-guess.\n",
    "- `exclude_features`: Lists columns (like `Latitude`, `Longitude`, `id`) that should *not*\n",
    "  be imputed because they are unique or spatial constants.\n",
    "- `k_nn`: The number of neighbors to consider (default is 5).\n",
    "- `create_correlation`: When True, imputation is performed sequentially in batches.\n",
    "  The first batch of imputed buildings becomes part of the \"truth\" for the next batch,\n",
    "  ensuring that neighborhoods develop consistent, spatially correlated characteristics\n",
    "  rather than random noise."
   ],
   "id": "f1bf6f7e9fbb2e0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from brails.imputers import KnnImputer\n",
    "\n",
    "bldg_inventory_imputed = KnnImputer(\n",
    "    bldg_inventory,\n",
    "    n_possible_worlds=1,\n",
    "    exclude_features=['Latitude','Longitude','fd_id','id']\n",
    ").impute()"
   ],
   "id": "ec8f3b51bcc0bc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Generate Probabilistic Households\n",
    "\n",
    "This step populates residential buildings with probabilistic households.\n",
    "The `PyncodaHousingUnitAllocator` acts as a bridge to the **`pyncoda`** library.\n",
    "\n",
    "**What does `pyncoda` do?**\n",
    "It downloads US Census demographic data and generates a probabilistic population\n",
    "that statistically matches the local census block. It then assigns those households\n",
    "to the residential buildings in our inventory.\n",
    "\n",
    "**Configuration:**\n",
    "- `vintage`: Which Census year to use ('2010' or '2020').\n",
    "- `key_features`: Tells `pyncoda` which columns in *our* inventory correspond to the\n",
    "  building traits it needs (Occupancy, Area, Stories) to make intelligent assignments.\n",
    "- `seed`: Ensures the random generation is reproducible.\n",
    "- `clean_work_dir`: When `True`, creates a fresh working environment. Set to `False`\n",
    "  to reuse downloaded Census data for faster re-runs on the same location."
   ],
   "id": "2afcc2aa466b7c32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from brails.aggregators import PyncodaHousingUnitAllocator\n",
    "from pathlib import Path\n",
    "\n",
    "work_dir = Path.cwd() / \"pyncoda_working_dir\"\n",
    "\n",
    "PyncodaHousingUnitAllocator(\n",
    "    inventory=bldg_inventory_imputed,\n",
    "    vintage='2020',\n",
    "    seed=9878,\n",
    "    key_features=dict(\n",
    "        occupancy_col=\"OccupancyClass\",\n",
    "        plan_area_col=\"PlanArea\",\n",
    "        story_count_col=\"NumberOfStories\",\n",
    "        length_unit=\"ft\",\n",
    "    ),\n",
    "    work_dir=str(work_dir),\n",
    "    clean_work_dir=True\n",
    ").allocate()"
   ],
   "id": "88aa4aaf24682aef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Summarize Household Data\n",
    "\n",
    "Aggregate household stats (Population, Income, etc.) back to the building assets.\n",
    "This flattens the detailed data into scalar building attributes to facilitate visualization."
   ],
   "id": "1bf32e20589fec5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from brails.aggregators import PyncodaHousingUnitSummarizer\n",
    "\n",
    "PyncodaHousingUnitSummarizer(bldg_inventory_imputed).summarize()"
   ],
   "id": "57af32ee51209cd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8. Export Results\n",
    "\n",
    "Finally, we save our work to local files:\n",
    "- **`bldg_inventory.geojson`**: The physical building inventory. Buildings with\n",
    "  assigned households will contain a `HousingUnits` field with a list of IDs.\n",
    "- **`housing_units.json`**: The demographic inventory. This file contains detailed\n",
    "  attributes (e.g., `Ownership`, `Race`, `IncomeGroup`) for every household ID.\n",
    "\n",
    "These two files are linked relationally by these IDs."
   ],
   "id": "c3a09a55caf63672"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Buildings\n",
    "bldg_inventory_imputed.write_to_geojson('bldg_inventory.geojson')\n",
    "\n",
    "# Housing Units\n",
    "bldg_inventory_imputed.housing_unit_inventory.to_json('housing_units.json')"
   ],
   "id": "6ae20ec3f57e067a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c668232b0d4c27ff",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
